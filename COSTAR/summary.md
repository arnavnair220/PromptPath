2/12-3/30: Summary of COSTAR prompt changes so far (instructed to make summary file on 3/18)

The first week (2/12-2/19) was understanding what prompt engineering is. In order to do this for COSTAR, we read some articles shared by PromptPath that dived deep into prompt engineering and the COSTAR model specifically. After that, we started getting our hands dirty by just trying prompt engineering out for ourselves by making some basic prompts for some of the questions on the rubric.

The second week (2/19-2/26) we continued working on the easier parts of the rubric and started fleshing out our prompts. I worked on the COSTAR model, and had answered most of the 'easy' questions on the rubric by now with relatively decent accuracy (around 10-12 questions on the rubric and therefore the prompt).

The third week (2/26-03/04) was when we really started getting the gears moving. I made significant changes to most of the easier questions to ensure higher accuracy, and then proceeded to start working on some more questions from the rubric. While doing this, I kept on running into problems with inconsistent results, and therefore had to keep tweaking my prompts to make them more consistent.

The next couple of weeks (03/04-03/20) saw a lot of changes. We received an amended rubric, which changed things from a point based system with weightage to each prompt to an atomic rubric. Because of this, I changed all my prompts to match the new output specification. I also ended up making quite a few changes to the prompts over the course of these weeks as they seemed to work more consistently with every small change I made. Most of the rubric has now been answered pretty accurately and consistently by the model (~88% overall accuracy). There are however a few questions left to tackle from the rubric, and that will be my focus for the next week or so.

3/20 - 3/30 was focused on solving the last few parts of the rubric (6 or so questions). This was done with testing multiple different examples, as the example (multishot prompting) given to the prompt changed results every time. Finding the right example might be a longer process, and once we test the current complete COSTAR prompt against the chats, we'll know exactly which parts of the rubric need more work. I continued working on grading some manual chats over this week, along with refining the prompt. 

3/30-04/05: worked on refining costar prompt by adding examples and redifining structures. Also worked on grading more manual chats. 
